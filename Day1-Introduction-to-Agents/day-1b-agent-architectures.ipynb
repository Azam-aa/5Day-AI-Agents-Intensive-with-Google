{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:01.697299Z","iopub.execute_input":"2025-11-10T09:23:01.697575Z","iopub.status.idle":"2025-11-10T09:23:01.702070Z","shell.execute_reply.started":"2025-11-10T09:23:01.697545Z","shell.execute_reply":"2025-11-10T09:23:01.701259Z"}},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"# üöÄ Multi-Agent Systems & Workflow Patterns\n\n**Welcome to the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you built a **single agent** that could take action. Now, you'll learn how to scale up by building **agent teams**.\n\nJust like a team of people, you can create specialized agents that collaborate to solve complex problems. This is called a **multi-agent system**, and it's one of the most powerful concepts in AI agent development.\n\nIn this notebook, you'll:\n\n- ‚úÖ Learn when to use multi-agent systems in [Agent Development Kit (ADK)](https://google.github.io/adk-docs/)\n- ‚úÖ Build your first system using an LLM as a \"manager\"\n- ‚úÖ Learn three core workflow patterns (Sequential, Parallel, and Loop) to coordinate your agent teams\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"### Section 1\n\n## ‚öôÔ∏è Setup\n\n### Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"code","source":"pip install google-adk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:01.703055Z","iopub.execute_input":"2025-11-10T09:23:01.704071Z","iopub.status.idle":"2025-11-10T09:23:06.444727Z","shell.execute_reply.started":"2025-11-10T09:23:01.704048Z","shell.execute_reply":"2025-11-10T09:23:06.443614Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: google-adk in /usr/local/lib/python3.11/dist-packages (1.18.0)\nRequirement already satisfied: PyYAML<7.0.0,>=6.0.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.3)\nRequirement already satisfied: anyio<5.0.0,>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.11.0)\nRequirement already satisfied: authlib<2.0.0,>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.6.5)\nRequirement already satisfied: click<9.0.0,>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from google-adk) (8.3.0)\nRequirement already satisfied: fastapi<1.119.0,>=0.115.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.116.1)\nRequirement already satisfied: google-api-python-client<3.0.0,>=2.157.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.177.0)\nRequirement already satisfied: google-cloud-aiplatform<2.0.0,>=1.125.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.125.0)\nRequirement already satisfied: google-cloud-bigtable>=2.32.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-discoveryengine<0.14.0,>=0.13.12 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.13.12)\nRequirement already satisfied: google-cloud-secret-manager<3.0.0,>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.25.0)\nRequirement already satisfied: google-cloud-spanner<4.0.0,>=3.56.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.56.0)\nRequirement already satisfied: google-cloud-speech<3.0.0,>=2.30.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.34.0)\nRequirement already satisfied: google-cloud-storage<4.0.0,>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (3.5.0)\nRequirement already satisfied: google-genai<2.0.0,>=1.45.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.48.0)\nRequirement already satisfied: graphviz<1.0.0,>=0.20.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.21)\nRequirement already satisfied: mcp<2.0.0,>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.20.0)\nRequirement already satisfied: opentelemetry-api<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-exporter-gcp-logging<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-exporter-gcp-trace<2.0.0,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.36.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-resourcedetector-gcp<2.0.0,>=1.9.0a0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.11.0a0)\nRequirement already satisfied: opentelemetry-sdk<=1.37.0,>=1.37.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.37.0)\nRequirement already satisfied: pydantic<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.12.4)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.9.0.post0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.9.0.post0)\nRequirement already satisfied: python-dotenv<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.2.1)\nRequirement already satisfied: requests<3.0.0,>=2.32.4 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.32.5)\nRequirement already satisfied: sqlalchemy-spanner>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (1.17.1)\nRequirement already satisfied: sqlalchemy<3.0.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (2.0.41)\nRequirement already satisfied: starlette<1.0.0,>=0.46.2 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.47.2)\nRequirement already satisfied: tenacity<10.0.0,>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (9.1.2)\nRequirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.11/dist-packages (from google-adk) (4.15.0)\nRequirement already satisfied: tzlocal<6.0,>=5.3 in /usr/local/lib/python3.11/dist-packages (from google-adk) (5.3.1)\nRequirement already satisfied: uvicorn<1.0.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (0.35.0)\nRequirement already satisfied: watchdog<7.0.0,>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from google-adk) (6.0.0)\nRequirement already satisfied: websockets<16.0.0,>=15.0.1 in /usr/local/lib/python3.11/dist-packages (from google-adk) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (3.11)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0.0,>=4.9.0->google-adk) (1.3.1)\nRequirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<2.0.0,>=1.5.1->google-adk) (46.0.3)\nRequirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.22.0)\nRequirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.38.0)\nRequirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.2.0)\nRequirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (2.28.1)\nRequirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.2.0)\nRequirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.1)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (5.29.5)\nRequirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (25.0)\nRequirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0,>=1.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.35.1)\nRequirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.14.2)\nRequirement already satisfied: shapely<3.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.1.2)\nRequirement already satisfied: docstring_parser<1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.17.0)\nRequirement already satisfied: cloudpickle<4.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.1.2)\nRequirement already satisfied: google-cloud-trace<2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.17.0)\nRequirement already satisfied: google-cloud-logging<4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (3.12.1)\nRequirement already satisfied: google-cloud-core<3.0.0,>=1.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (2.4.3)\nRequirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (0.14.2)\nRequirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigtable>=2.32.0->google-adk) (1.7.1)\nRequirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-secret-manager<3.0.0,>=2.22.0->google-adk) (1.74.0)\nRequirement already satisfied: sqlparse>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.5.3)\nRequirement already satisfied: grpc-interceptor>=0.15.4 in /usr/local/lib/python3.11/dist-packages (from google-cloud-spanner<4.0.0,>=3.56.0->google-adk) (0.15.4)\nRequirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage<4.0.0,>=3.0.0->google-adk) (2.7.2)\nRequirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai<2.0.0,>=1.45.0->google-adk) (0.28.1)\nRequirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.4.3)\nRequirement already satisfied: jsonschema>=4.20.0 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (4.25.0)\nRequirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (2.11.0)\nRequirement already satisfied: pyjwt>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.10.1->mcp<2.0.0,>=1.8.0->google-adk) (2.10.1)\nRequirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (0.0.20)\nRequirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from mcp<2.0.0,>=1.8.0->google-adk) (3.0.3)\nRequirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (8.7.0)\nRequirement already satisfied: google-cloud-monitoring~=2.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-gcp-monitoring<2.0.0,>=1.9.0a0->google-adk) (2.28.0)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.70.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.36.0->google-adk) (1.37.0)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<=1.37.0,>=1.37.0->google-adk) (0.58b0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0->google-adk) (0.4.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.9.0.post0->google-adk) (1.17.0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.32.4->google-adk) (2025.10.5)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3.0.0,>=2.0->google-adk) (3.2.3)\nRequirement already satisfied: alembic in /usr/local/lib/python3.11/dist-packages (from sqlalchemy-spanner>=1.14.0->google-adk) (1.17.1)\nRequirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1.0.0,>=0.34.0->google-adk) (0.16.0)\nRequirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.71.2)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (4.9.1)\nRequirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.7.0)\nRequirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-logging<4->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.4.0)\nRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (3.0.9)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.45.0->google-adk) (1.0.9)\nRequirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<=1.37.0,>=1.37.0->google-adk) (3.23.0)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (25.4.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (2025.4.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.20.0->mcp<2.0.0,>=1.8.0->google-adk) (0.26.0)\nRequirement already satisfied: cffi>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.0.0)\nRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.11/dist-packages (from shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.26.4)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic->sqlalchemy-spanner>=1.14.0->google-adk) (1.3.10)\nRequirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=2.0.0->cryptography->authlib<2.0.0,>=1.5.1->google-adk) (2.23)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2.4.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=1.32.0->google-api-python-client<3.0.0,>=2.157.0->google-adk) (0.6.1)\nRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.11/dist-packages (from Mako->alembic->sqlalchemy-spanner>=1.14.0->google-adk) (3.0.3)\nRequirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2025.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2022.3.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (1.4.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21->shapely<3.0.0->google-cloud-aiplatform<2.0.0,>=1.125.0->google-cloud-aiplatform[agent-engines]<2.0.0,>=1.125.0->google-adk) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"markdown","source":"### 1.1 Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    os.environ[\"GOOGLE_GENAI_USE_VERTEXAI\"] = \"FALSE\"\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:06.445890Z","iopub.execute_input":"2025-11-10T09:23:06.446145Z","iopub.status.idle":"2025-11-10T09:23:06.527081Z","shell.execute_reply.started":"2025-11-10T09:23:06.446119Z","shell.execute_reply":"2025-11-10T09:23:06.526134Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":49},{"cell_type":"markdown","source":"### 1.2 Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import Agent, SequentialAgent, ParallelAgent, LoopAgent\nfrom google.adk.runners import InMemoryRunner\nfrom google.adk.tools import AgentTool, FunctionTool, google_search\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:06.527905Z","iopub.execute_input":"2025-11-10T09:23:06.528119Z","iopub.status.idle":"2025-11-10T09:23:06.533866Z","shell.execute_reply.started":"2025-11-10T09:23:06.528102Z","shell.execute_reply":"2025-11-10T09:23:06.532863Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":50},{"cell_type":"markdown","source":"---\n### Section 2\n\n## ü§î Why Multi-Agent Systems? + Your First Multi-Agent","metadata":{}},{"cell_type":"markdown","source":"**The Problem: The \"Do-It-All\" Agent**\n\nSingle agents can do a lot. But what happens when the task gets complex? A single \"monolithic\" agent that tries to do research, writing, editing, and fact-checking all at once becomes a problem. Its instruction prompt gets long and confusing. It's hard to debug (which part failed?), difficult to maintain, and often produces unreliable results.\n\n**The Solution: A Team of Specialists**\n\nInstead of one \"do-it-all\" agent, we can build a **multi-agent system**. This is a team of simple, specialized agents that collaborate, just like a real-world team. Each agent has one clear job (e.g., one agent *only* does research, another *only* writes). This makes them easier to build, easier to test, and much more powerful and reliable when working together.\n\nTo learn more, check out the documentation related to [LLM agents in ADK](https://google.github.io/adk-docs/agents/llm-agents/).\n\n**Architecture: Single Agent vs Multi-Agent Team**\n\n<!--\n```mermaid\ngraph TD\n    subgraph Single[\"‚ùå Monolithic Agent\"]\n        A[\"One Agent Does Everything\"]\n    end\n\n    subgraph Multi[\"‚úÖ Multi-Agent Team\"]\n        B[\"Root Coordinator\"] -- > C[\"Research Specialist\"]\n        B -- > E[\"Summary Specialist\"]\n\n        C -- >|findings| F[\"Shared State\"]\n        E -- >|summary| F\n    end\n\n    style A fill:#ffcccc\n    style B fill:#ccffcc\n    style F fill:#ffffcc\n```\n-->","metadata":{}},{"cell_type":"markdown","source":"<img width=\"800\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/multi-agent-team.png\" alt=\"Multi-agent Team\" />","metadata":{}},{"cell_type":"markdown","source":"### 2.1 Example: Research & Summarization System\n\nLet's build a system with two specialized agents:\n\n1. **Research Agent** - Searches for information using Google Search\n2. **Summarizer Agent** - Creates concise summaries from research findings","metadata":{}},{"cell_type":"code","source":"# Research Agent: Its job is to use the google_search tool and present findings.\nresearch_agent = Agent(\n    name=\"ResearchAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a specialized research agent. Your only job is to use the\n    google_search tool to find 2-3 pieces of relevant information on the given topic and present the findings with citations.\"\"\",\n    tools=[google_search],\n    output_key=\"research_findings\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ research_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:06.535297Z","iopub.execute_input":"2025-11-10T09:23:06.535797Z","iopub.status.idle":"2025-11-10T09:23:06.551936Z","shell.execute_reply.started":"2025-11-10T09:23:06.535776Z","shell.execute_reply":"2025-11-10T09:23:06.551080Z"}},"outputs":[{"name":"stdout","text":"‚úÖ research_agent created.\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# Summarizer Agent: Its job is to summarize the text it receives.\nsummarizer_agent = Agent(\n    name=\"SummarizerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The instruction is modified to request a bulleted list for a clear output format.\n    instruction=\"\"\"Read the provided research findings: {research_findings}\nCreate a concise summary as a bulleted list with 3-5 key points.\"\"\",\n    output_key=\"final_summary\",\n)\n\nprint(\"‚úÖ summarizer_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:06.553520Z","iopub.execute_input":"2025-11-10T09:23:06.553886Z","iopub.status.idle":"2025-11-10T09:23:06.574712Z","shell.execute_reply.started":"2025-11-10T09:23:06.553854Z","shell.execute_reply":"2025-11-10T09:23:06.573351Z"}},"outputs":[{"name":"stdout","text":"‚úÖ summarizer_agent created.\n","output_type":"stream"}],"execution_count":52},{"cell_type":"markdown","source":"Refer to the ADK documentation for more information on [guiding agents with clear and specific instructions](https://google.github.io/adk-docs/agents/llm-agents/).\n\nThen we bring the agents together under a root agent, or coordinator:","metadata":{}},{"cell_type":"code","source":"# Root Coordinator: Orchestrates the workflow by calling the sub-agents as tools.\nroot_agent = Agent(\n    name=\"ResearchCoordinator\",\n    model=\"gemini-2.5-flash-lite\",\n    # This instruction tells the root agent HOW to use its tools (which are the other agents).\n    instruction=\"\"\"You are a research coordinator. Your goal is to answer the user's query by orchestrating a workflow.\n1. First, you MUST call the `ResearchAgent` tool to find relevant information on the topic provided by the user.\n2. Next, after receiving the research findings, you MUST call the `SummarizerAgent` tool to create a concise summary.\n3. Finally, present the final summary clearly to the user as your response.\"\"\",\n    # We wrap the sub-agents in `AgentTool` to make them callable tools for the root agent.\n    tools=[\n        AgentTool(research_agent),\n        AgentTool(summarizer_agent)\n    ],\n)\n\nprint(\"‚úÖ root_agent created.\")","metadata":{"id":"PKthuzRkBtHD","outputId":"dee6d4cc-17b4-4430-8454-d56096fbe360","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:06.575831Z","iopub.execute_input":"2025-11-10T09:23:06.576060Z","iopub.status.idle":"2025-11-10T09:23:06.594044Z","shell.execute_reply.started":"2025-11-10T09:23:06.576031Z","shell.execute_reply":"2025-11-10T09:23:06.593080Z"}},"outputs":[{"name":"stdout","text":"‚úÖ root_agent created.\n","output_type":"stream"}],"execution_count":53},{"cell_type":"markdown","source":"Here we're using `AgentTool` to wrap the sub-agents to make them callable tools for the root agent. We'll explore `AgentTool` in-detail on Day 2.\n\nLet's run the agent and ask it about a topic:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"What are the latest advancements in quantum computing and what do they mean for AI?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:06.594979Z","iopub.execute_input":"2025-11-10T09:23:06.595358Z","iopub.status.idle":"2025-11-10T09:23:14.994167Z","shell.execute_reply.started":"2025-11-10T09:23:06.595324Z","shell.execute_reply":"2025-11-10T09:23:14.993231Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > What are the latest advancements in quantum computing and what do they mean for AI?\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\nWARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"ResearchCoordinator > The integration of quantum computing with Artificial Intelligence, known as Quantum AI, is rapidly advancing and promises to revolutionize various sectors. Quantum computers, utilizing qubits, offer exponential speedups for complex computations, leading to faster AI model training and more efficient data processing. This can result in AI models that are as effective as classical ones but require fewer parameters and less computational power.\n\nKey advancements and their implications include:\n\n*   **Enhanced AI Performance:** Quantum computing significantly boosts AI's ability to solve complex optimization problems, which is crucial for fields like drug discovery, materials science, finance, and logistics.\n*   **Sector-Specific Transformations:** The impact is far-reaching, with potential revolutions in healthcare for personalized medicine and drug discovery, in finance for risk assessment and portfolio optimization, and in manufacturing and logistics for optimizing supply chains.\n*   **Hybrid Systems and AI's Role:** Near-term progress is expected through hybrid quantum-classical computing systems. Additionally, AI is playing a role in advancing quantum computing itself by improving error correction and hardware optimization.\n*   **Ongoing Challenges:** Despite the rapid progress, challenges such as maintaining qubit coherence, scaling quantum hardware, and developing specialized talent and algorithms need to be addressed. Widespread commercial adoption is not anticipated within the next decade.\n","output_type":"stream"}],"execution_count":54},{"cell_type":"markdown","source":"You've just built your first multi-agent system! You used a single \"coordinator\" agent to manage the workflow, which is a powerful and flexible pattern.\n\n‚ÄºÔ∏è However, **relying on an LLM's instructions to control the order can sometimes be unpredictable.** Next, we'll explore a different pattern that gives you guaranteed, step-by-step execution.","metadata":{}},{"cell_type":"markdown","source":"---\n\n### Section 3\n## üö• Sequential Workflows - The Assembly Line\n\n**The Problem: Unpredictable Order**\n\nThe previous multi-agent system worked, but it relied on a **detailed instruction prompt** to force the LLM to run steps in order. This can be unreliable. A complex LLM might decide to skip a step, run them in the wrong order, or get \"stuck,\" making the process unpredictable.\n\n**The Solution: A Fixed Pipeline**\n\nWhen you need tasks to happen in a **guaranteed, specific order**, you can use a `SequentialAgent`. This agent acts like an assembly line, running each sub-agent in the exact order you list them. The output of one agent automatically becomes the input for the next, creating a predictable and reliable workflow.\n\n**Use Sequential when:** Order matters, you need a linear pipeline, or each step builds on the previous one.\n\nTo learn more, check out the documentation related to [sequential agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/).\n\n**Architecture: Blog Post Creation Pipeline**\n\n<!--\n```mermaid\ngraph LR\n    A[\"User Input: Blog about AI\"] -- > B[\"Outline Agent\"]\n    B -- >|blog_outline| C[\"Writer Agent\"]\n    C -- >|blog_draft| D[\"Editor Agent\"]\n    D -- >|final_blog| E[\"Output\"]\n\n    style B fill:#ffcccc\n    style C fill:#ccffcc\n    style D fill:#ccccff\n```\n-->","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/sequential-agent.png\" alt=\"Sequential Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Example: Blog Post Creation with Sequential Agents\n\nLet's build a system with three specialized agents:\n\n1. **Outline Agent** - Creates a blog outline for a given topic\n2. **Writer Agent** - Writes a blog post\n3. **Editor Agent** - Edits a blog post draft for clarity and structure","metadata":{"id":"h6Bcds7EBtHE"}},{"cell_type":"code","source":"# Outline Agent: Creates the initial blog post outline.\noutline_agent = Agent(\n    name=\"OutlineAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Create a blog outline for the given topic with:\n    1. A catchy headline\n    2. An introduction hook\n    3. 3-5 main sections with 2-3 bullet points for each\n    4. A concluding thought\"\"\",\n    output_key=\"blog_outline\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ outline_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:14.995043Z","iopub.execute_input":"2025-11-10T09:23:14.995248Z","iopub.status.idle":"2025-11-10T09:23:15.000398Z","shell.execute_reply.started":"2025-11-10T09:23:14.995232Z","shell.execute_reply":"2025-11-10T09:23:14.999344Z"}},"outputs":[{"name":"stdout","text":"‚úÖ outline_agent created.\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"# Writer Agent: Writes the full blog post based on the outline from the previous agent.\nwriter_agent = Agent(\n    name=\"WriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # The `{blog_outline}` placeholder automatically injects the state value from the previous agent's output.\n    instruction=\"\"\"Following this outline strictly: {blog_outline}\n    Write a brief, 200 to 300-word blog post with an engaging and informative tone.\"\"\",\n    output_key=\"blog_draft\", # The result of this agent will be stored with this key.\n)\n\nprint(\"‚úÖ writer_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:15.001288Z","iopub.execute_input":"2025-11-10T09:23:15.001520Z","iopub.status.idle":"2025-11-10T09:23:15.018891Z","shell.execute_reply.started":"2025-11-10T09:23:15.001502Z","shell.execute_reply":"2025-11-10T09:23:15.017930Z"}},"outputs":[{"name":"stdout","text":"‚úÖ writer_agent created.\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"# Editor Agent: Edits and polishes the draft from the writer agent.\neditor_agent = Agent(\n    name=\"EditorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # This agent receives the `{blog_draft}` from the writer agent's output.\n    instruction=\"\"\"Edit this draft: {blog_draft}\n    Your task is to polish the text by fixing any grammatical errors, improving the flow and sentence structure, and enhancing overall clarity.\"\"\",\n    output_key=\"final_blog\", # This is the final output of the entire pipeline.\n)\n\nprint(\"‚úÖ editor_agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:15.019998Z","iopub.execute_input":"2025-11-10T09:23:15.020882Z","iopub.status.idle":"2025-11-10T09:23:15.038530Z","shell.execute_reply.started":"2025-11-10T09:23:15.020857Z","shell.execute_reply":"2025-11-10T09:23:15.037692Z"}},"outputs":[{"name":"stdout","text":"‚úÖ editor_agent created.\n","output_type":"stream"}],"execution_count":57},{"cell_type":"markdown","source":"Then we bring the agents together under a sequential agent, which runs the agents in the order that they are listed:","metadata":{}},{"cell_type":"code","source":"root_agent = SequentialAgent(\n    name=\"BlogPipeline\",\n    sub_agents=[outline_agent, writer_agent, editor_agent],\n)\n\nprint(\"‚úÖ Sequential Agent created.\")","metadata":{"id":"TLflGqQVBtHE","outputId":"b671e4da-e69d-44f0-bf3b-85dc7cb51496","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:15.039433Z","iopub.execute_input":"2025-11-10T09:23:15.039743Z","iopub.status.idle":"2025-11-10T09:23:15.059332Z","shell.execute_reply.started":"2025-11-10T09:23:15.039716Z","shell.execute_reply":"2025-11-10T09:23:15.058454Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Sequential Agent created.\n","output_type":"stream"}],"execution_count":58},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a blog post about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a blog post about the benefits of multi-agent systems for software developers\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:15.060225Z","iopub.execute_input":"2025-11-10T09:23:15.060589Z","iopub.status.idle":"2025-11-10T09:23:21.720475Z","shell.execute_reply.started":"2025-11-10T09:23:15.060561Z","shell.execute_reply":"2025-11-10T09:23:21.719657Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a blog post about the benefits of multi-agent systems for software developers\nOutlineAgent > Here's a blog post outline about the benefits of multi-agent systems for software developers:\n\n## Headline: Unleash Your Software's Potential: Why Multi-Agent Systems Are Your Next Game-Changer\n\n**Introduction Hook:** Imagine a software system that can autonomously adapt, learn, and collaborate to solve complex problems. Sounds like science fiction? It's not. Multi-agent systems (MAS) are no longer a niche academic concept; they are a powerful paradigm offering tangible benefits to software developers looking to build more robust, intelligent, and efficient applications. Let's dive into why you should be paying attention.\n\n---\n\n### Section 1: Enhanced Problem Decomposition and Modularity\n\n*   **Breaking Down Complexity:** MAS allows for the natural decomposition of large, intricate problems into smaller, manageable sub-problems, each handled by an independent agent. This significantly simplifies development and maintenance.\n*   **Independent Development & Testing:** Each agent can be developed, tested, and deployed independently, accelerating development cycles and reducing the risk of cascading failures.\n*   **Reusability and Interoperability:** Well-defined agents with clear communication protocols can be easily reused across different projects or integrated with existing systems, fostering a more modular and adaptable software ecosystem.\n\n### Section 2: Increased Robustness and Resilience\n\n*   **Decentralized Control:** Unlike monolithic systems, MAS often operate with decentralized control. If one agent fails, the system can often continue to function, gracefully degrading or rerouting tasks to other agents.\n*   **Fault Tolerance and Self-Healing:** Agents can be designed to detect failures in their peers and initiate recovery processes, leading to highly fault-tolerant and even self-healing systems.\n*   **Adaptability to Dynamic Environments:** MAS excels in environments where conditions change frequently. Agents can react to new information and adjust their behavior, making the overall system more adaptable and resilient to unforeseen circumstances.\n\n### Section 3: Sophisticated Collaboration and Intelligence\n\n*   **Emergent Behavior:** The interaction and collaboration between multiple agents can lead to emergent behaviors and solutions that are far more sophisticated than what any single agent could achieve alone.\n*   **Distributed Decision-Making:** Complex decisions can be made collaboratively by multiple agents, leveraging their individual expertise and perspectives for more informed and optimized outcomes.\n*   **Learning and Adaptation at Scale:** MAS provides a natural framework for distributed machine learning, where individual agents can learn from their experiences and share knowledge, leading to a system that continuously improves its performance over time.\n\n### Section 4: New Avenues for Innovation and Application\n\n*   **Simulating Complex Real-World Scenarios:** MAS is ideal for modeling and simulating complex systems like supply chains, traffic control, or ecological interactions, opening doors for predictive analytics and optimization.\n*   **Intelligent Automation and Robotics:** From smart grids to autonomous vehicles, MAS is the backbone of many advanced automation and robotics applications requiring coordination and intelligent interaction.\n*   **Enhanced User Experiences:** Imagine personalized assistants that collaborate to fulfill your needs, or adaptive user interfaces that tailor themselves to your behavior ‚Äì MAS can power next-generation, intuitive user experiences.\n\n---\n\n**Concluding Thought:** Embracing multi-agent systems isn't just about adopting a new technology; it's about adopting a new way of thinking about software design and development. By leveraging the power of decentralized intelligence, collaboration, and modularity, you can build software that is not only more powerful and resilient but also more adaptable to the ever-evolving challenges of the digital world. Are you ready to let your agents do the heavy lifting?\nWriterAgent > ## Unleash Your Software's Potential: Why Multi-Agent Systems Are Your Next Game-Changer\n\nImagine a software system that can autonomously adapt, learn, and collaborate to solve complex problems. Sounds like science fiction? It's not. Multi-agent systems (MAS) are no longer a niche academic concept; they are a powerful paradigm offering tangible benefits to software developers looking to build more robust, intelligent, and efficient applications. Let's dive into why you should be paying attention.\n\nMAS allows for the natural **decomposition of complex problems** into smaller, manageable sub-problems, each handled by an independent agent. This dramatically simplifies development and maintenance, allowing for independent testing and deployment of each agent, thus accelerating cycles. Furthermore, well-defined agents with clear communication protocols foster **reusability and interoperability**, creating a more adaptable software ecosystem.\n\nBeyond development efficiency, MAS boosts **robustness and resilience**. With decentralized control, the failure of one agent doesn't necessarily bring down the entire system. Agents can be designed for **fault tolerance and self-healing**, gracefully degrading or rerouting tasks. This makes MAS exceptionally well-suited for dynamic environments where systems must constantly adapt to changing conditions.\n\nThe true magic of MAS lies in **sophisticated collaboration and intelligence**. The interaction between agents can lead to emergent behaviors and solutions far beyond what any single agent could achieve. This enables **distributed decision-making**, leveraging diverse expertise for optimized outcomes. MAS also provides a natural framework for **learning and adaptation at scale**, where agents collectively improve performance over time.\n\nEmbracing MAS isn't just about new tech; it's a shift in thinking. By leveraging decentralized intelligence, collaboration, and modularity, you can build software that is more powerful, resilient, and adaptable. Are you ready to let your agents do the heavy lifting?\nEditorAgent > ## Unleash Your Software's Potential: Why Multi-Agent Systems Are Your Next Game-Changer\n\nImagine a software system that can autonomously adapt, learn, and collaborate to solve complex problems. Sounds like science fiction? It's not. Multi-agent systems (MAS) are no longer a niche academic concept; they are a powerful paradigm offering tangible benefits to software developers looking to build more robust, intelligent, and efficient applications. Let's dive into why you should be paying attention.\n\n### Break Down Complexity, Build with Agility\n\nMAS allows for the natural **decomposition of complex problems** into smaller, manageable sub-problems, each handled by an independent agent. This dramatically simplifies development and maintenance. Each agent can be developed, tested, and deployed independently, which in turn accelerates development cycles and reduces the risk of cascading failures. Furthermore, well-defined agents with clear communication protocols foster **reusability and interoperability**, creating a more modular and adaptable software ecosystem.\n\n### Build Systems That Withstand the Storm\n\nBeyond development efficiency, MAS boosts **robustness and resilience**. Unlike monolithic systems, MAS often operate with decentralized control. This means that the failure of one agent doesn't necessarily bring down the entire system. Agents can be designed for **fault tolerance and self-healing**, gracefully degrading or rerouting tasks to other agents. This makes MAS exceptionally well-suited for dynamic environments where systems must constantly adapt to changing conditions.\n\n### Unlock Collective Intelligence and Emergent Solutions\n\nThe true magic of MAS lies in **sophisticated collaboration and intelligence**. The interaction and collaboration between multiple agents can lead to emergent behaviors and solutions that are far beyond what any single agent could achieve alone. This enables **distributed decision-making**, leveraging diverse expertise for optimized outcomes. MAS also provides a natural framework for **learning and adaptation at scale**, where agents collectively improve performance over time.\n\n### Embracing the Future of Software Development\n\nEmbracing multi-agent systems isn't just about adopting a new technology; it's about adopting a new way of thinking about software design and development. By leveraging the power of decentralized intelligence, collaboration, and modularity, you can build software that is not only more powerful and resilient but also more adaptable to the ever-evolving challenges of the digital world. Are you ready to let your agents do the heavy lifting?\n","output_type":"stream"}],"execution_count":59},{"cell_type":"markdown","source":"üëè Great job! You've now created a reliable \"assembly line\" using a sequential agent, where each step runs in a predictable order.\n\n**This is perfect for tasks that build on each other, but it's slow if the tasks are independent.** Next, we'll look at how to run multiple agents at the same time to speed up your workflow.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 4\n## üõ£Ô∏è Parallel Workflows - Independent Researchers\n\n**The Problem: The Bottleneck**\n\nThe previous sequential agent is great, but it's an assembly line. Each step must wait for the previous one to finish. What if you have several tasks that are **not dependent** on each other? For example, researching three *different* topics. Running them in sequence would be slow and inefficient, creating a bottleneck where each task waits unnecessarily.\n\n**The Solution: Concurrent Execution**\n\nWhen you have independent tasks, you can run them all at the same time using a `ParallelAgent`. This agent executes all of its sub-agents concurrently, dramatically speeding up the workflow. Once all parallel tasks are complete, you can then pass their combined results to a final 'aggregator' step.\n\n**Use Parallel when:** Tasks are independent, speed matters, and you can execute concurrently.\n\nTo learn more, check out the documentation related to [parallel agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/).\n\n**Architecture: Multi-Topic Research**\n\n<!--\n```mermaid\ngraph TD\n    A[\"User Request: Research 3 topics\"] -- > B[\"Parallel Execution\"]\n    B -- > C[\"Tech Researcher\"]\n    B -- > D[\"Health Researcher\"]\n    B -- > E[\"Finance Researcher\"]\n\n    C -- > F[\"Aggregator\"]\n    D -- > F\n    E -- > F\n    F -- > G[\"Combined Report\"]\n\n    style B fill:#ffffcc\n    style F fill:#ffccff\n```\n-->","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"markdown","source":"<img width=\"600\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/parallel-agent.png\" alt=\"Parallel Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 4.1 Example: Parallel Multi-Topic Research\n\nLet's build a system with four agents:\n\n1. **Tech Researcher** - Researches AI/ML news and trends\n2. **Health Researcher** - Researches recent medical news and trends\n3. **Finance Researcher** - Researches finance and fintech news and trends\n4. **Aggregator Agent** - Combines all research findings into a single summary","metadata":{"id":"U37FxKxDBtHE"}},{"cell_type":"code","source":"# Tech Researcher: Focuses on AI and ML trends.\ntech_researcher = Agent(\n    name=\"TechResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research the latest AI/ML trends. Include 3 key developments,\nthe main companies involved, and the potential impact. Keep the report very concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"tech_research\", # The result of this agent will be stored in the session state with this key.\n)\n\nprint(\"‚úÖ tech_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:21.721391Z","iopub.execute_input":"2025-11-10T09:23:21.721757Z","iopub.status.idle":"2025-11-10T09:23:21.727504Z","shell.execute_reply.started":"2025-11-10T09:23:21.721735Z","shell.execute_reply":"2025-11-10T09:23:21.726622Z"}},"outputs":[{"name":"stdout","text":"‚úÖ tech_researcher created.\n","output_type":"stream"}],"execution_count":60},{"cell_type":"code","source":"# Health Researcher: Focuses on medical breakthroughs.\nhealth_researcher = Agent(\n    name=\"HealthResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research recent medical breakthroughs. Include 3 significant advances,\ntheir practical applications, and estimated timelines. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"health_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ health_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:21.728439Z","iopub.execute_input":"2025-11-10T09:23:21.728710Z","iopub.status.idle":"2025-11-10T09:23:21.748115Z","shell.execute_reply.started":"2025-11-10T09:23:21.728681Z","shell.execute_reply":"2025-11-10T09:23:21.747043Z"}},"outputs":[{"name":"stdout","text":"‚úÖ health_researcher created.\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"# Finance Researcher: Focuses on fintech trends.\nfinance_researcher = Agent(\n    name=\"FinanceResearcher\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Research current fintech trends. Include 3 key trends,\ntheir market implications, and the future outlook. Keep the report concise (100 words).\"\"\",\n    tools=[google_search],\n    output_key=\"finance_research\", # The result will be stored with this key.\n)\n\nprint(\"‚úÖ finance_researcher created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:21.749181Z","iopub.execute_input":"2025-11-10T09:23:21.749603Z","iopub.status.idle":"2025-11-10T09:23:21.768390Z","shell.execute_reply.started":"2025-11-10T09:23:21.749574Z","shell.execute_reply":"2025-11-10T09:23:21.767473Z"}},"outputs":[{"name":"stdout","text":"‚úÖ finance_researcher created.\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"# The AggregatorAgent runs *after* the parallel step to synthesize the results.\naggregator_agent = Agent(\n    name=\"AggregatorAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    # It uses placeholders to inject the outputs from the parallel agents, which are now in the session state.\n    instruction=\"\"\"Combine these three research findings into a single executive summary:\n\n    **Technology Trends:**\n    {tech_research}\n    \n    **Health Breakthroughs:**\n    {health_research}\n    \n    **Finance Innovations:**\n    {finance_research}\n    \n    Your summary should highlight common themes, surprising connections, and the most important key takeaways from all three reports. The final summary should be around 200 words.\"\"\",\n    output_key=\"executive_summary\", # This will be the final output of the entire system.\n)\n\nprint(\"‚úÖ aggregator_agent created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:21.769312Z","iopub.execute_input":"2025-11-10T09:23:21.769533Z","iopub.status.idle":"2025-11-10T09:23:21.788329Z","shell.execute_reply.started":"2025-11-10T09:23:21.769516Z","shell.execute_reply":"2025-11-10T09:23:21.787301Z"}},"outputs":[{"name":"stdout","text":"‚úÖ aggregator_agent created.\n","output_type":"stream"}],"execution_count":63},{"cell_type":"markdown","source":"üëâ **Then we bring the agents together under a parallel agent, which is itself nested inside of a sequential agent.**\n\nThis design ensures that the research agents run first in parallel, then once all of their research is complete, the aggregator agent brings together all of the research findings into a single report:","metadata":{}},{"cell_type":"code","source":"# The ParallelAgent runs all its sub-agents simultaneously.\nparallel_research_team = ParallelAgent(\n    name=\"ParallelResearchTeam\",\n    sub_agents=[tech_researcher, health_researcher, finance_researcher],\n)\n\n# This SequentialAgent defines the high-level workflow: run the parallel team first, then run the aggregator.\nroot_agent = SequentialAgent(\n    name=\"ResearchSystem\",\n    sub_agents=[parallel_research_team, aggregator_agent],\n)\n\nprint(\"‚úÖ Parallel and Sequential Agents created.\")","metadata":{"id":"GBhNDWZ9BtHE","outputId":"6fe3ae39-c6dc-4924-ab5f-59a58f09a8b5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:23:21.789408Z","iopub.execute_input":"2025-11-10T09:23:21.789736Z","iopub.status.idle":"2025-11-10T09:23:21.809439Z","shell.execute_reply.started":"2025-11-10T09:23:21.789703Z","shell.execute_reply":"2025-11-10T09:23:21.808440Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Parallel and Sequential Agents created.\n","output_type":"stream"}],"execution_count":64},{"cell_type":"markdown","source":"Let's run the agent and give it a prompt to research the given topics:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Run the daily executive briefing on Tech, Health, and Finance\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:24:06.197190Z","iopub.execute_input":"2025-11-10T09:24:06.197892Z","iopub.status.idle":"2025-11-10T09:24:13.680083Z","shell.execute_reply.started":"2025-11-10T09:24:06.197864Z","shell.execute_reply":"2025-11-10T09:24:13.679190Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Run the daily executive briefing on Tech, Health, and Finance\nHealthResearcher > Here are three recent medical breakthroughs with their applications and estimated timelines:\n\n1.  **CRISPR Gene Editing:** This technology allows for precise alteration of DNA, offering the potential to correct genetic diseases like sickle cell anemia and cystic fibrosis. Practical applications are emerging, with widespread use for treating genetic disorders anticipated within the next 5-10 years.\n\n2.  **mRNA Vaccine Technology:** Rapidly demonstrated with COVID-19 vaccines, mRNA technology is being explored for a broader range of diseases. Applications include vaccines for other infectious diseases and potentially cancer treatments, with further developments expected in the next 5-15 years.\n\n3.  **AI in Diagnostics:** Artificial intelligence is significantly enhancing medical imaging analysis and disease diagnosis. By identifying patterns invisible to the human eye, AI can lead to earlier and more accurate detection of conditions like cancer and stroke. Widespread integration into diagnostic workflows is expected within the next 3-7 years.\nTechResearcher > **AI/ML Trends Driving Innovation in 2025**\n\nThree key AI/ML developments are significantly shaping the technological landscape:\n\n1.  **Generative AI Advancement:** This trend focuses on AI's ability to create new content, including text, images, and video. Major players like **Google** (with Gemini) and **OpenAI** are at the forefront. The impact is a revolution in content creation, marketing, and even code generation, boosting productivity and enabling new forms of artistic expression.\n\n2.  **Agentic AI and Automation:** AI systems are increasingly capable of acting autonomously to complete tasks with minimal human intervention. This is driving significant automation across industries. Companies like **Microsoft** are heavily involved in developing these agentic ecosystems. The impact includes enhanced operational efficiency, particularly in areas like logistics and autonomous systems.\n\n3.  **Explainable AI (XAI):** As AI becomes more integrated into critical sectors like healthcare and finance, the demand for transparency in AI decision-making is growing. XAI aims to make AI systems interpretable and trustworthy. This trend is crucial for meeting regulatory requirements and fostering user trust.\n\nThese developments are powered by significant investment from tech giants such as **NVIDIA**, which provides the essential hardware (GPUs) for AI model training, and cloud providers like **Amazon** (AWS) and **Microsoft** (Azure), offering AI platforms and services. The overall impact is a more efficient, innovative, and increasingly automated future across various industries.\nFinanceResearcher > ## Tech Trends Executive Briefing\n\n**1. AI Workloads Driving Infrastructure Evolution:** The demand for AI, particularly large language models, is pushing a shift in infrastructure orchestration. Companies are investing heavily in GPUs and developing complex multi-stage pipelines to manage AI workloads, moving beyond basic cloud instances towards sophisticated orchestration strategies. This includes advancements in Kubernetes for AI specifically.\n\n*   **Market Implication:** Increased demand for specialized hardware and cloud services, driving innovation in infrastructure management software.\n*   **Future Outlook:** Continued growth in AI adoption will necessitate further advancements in efficient and scalable AI infrastructure.\n\n**2. Agentic AI and Context Engineering:** The trend is moving from simple chatbots to agentic AI systems capable of autonomous task execution. This requires sophisticated \"context engineering\" ‚Äì carefully structuring data for AI models. The Model Context Protocol (MCP) is becoming a standard for integrating AI with various systems.\n\n*   **Market Implication:** Rise of AI-powered automation and decision-making tools, impacting workflows across industries.\n*   **Future Outlook:** Agentic AI will become more sophisticated, leading to more autonomous systems and potentially new forms of human-AI collaboration.\n\n**3. Convergence of Physical and Digital (Phygital):** The integration of physical and digital experiences is a significant trend. This, alongside \"datafication\" turning operations into trackable insights, is reshaping how businesses interact with customers and manage processes. Emerging technologies like 5G, quantum computing, and green energy solutions also continue to evolve and reshape industries.\n\n*   **Market Implication:** Opportunities for new product development, enhanced customer experiences, and data-driven operational improvements.\n*   **Future Outlook:** The lines between the physical and digital will continue to blur, creating more immersive and data-rich environments.\n\n## Health Executive Briefing\n\n**1. Personalized Healthcare Revolution:** Beyond precision medicine, the trend is toward AI and data-driven personalized wellness plans and communication strategies to engage diverse patient groups.\n\n*   **Market Implication:** Growth in health tech, AI-driven diagnostics, and tailored health services.\n*   **Future Outlook:** Healthcare will become increasingly proactive and individualized, with a strong emphasis on preventative measures.\n\n**2. Technology in Mental Wellness:** A new wave of technological solutions, including VR/AR therapy sessions and 24/7 AI chatbots, aims to revolutionize mental healthcare delivery, addressing resource limitations and stigma.\n\n*   **Market Implication:** Expansion of digital mental health platforms and increased accessibility to support services.\n*   **Future Outlook:** Mental healthcare will integrate more seamlessly with technology, offering more convenient and stigma-free access to support.\n\n**3. Wearables 2.0: BCIs and Implants:** Brain-computer interfaces (BCIs) and implantable devices represent the next generation of health tech, showing promise for managing neurological conditions and other health challenges, though ethical considerations are paramount.\n\n*   **Market Implication:** Advancements in medical devices, neurotechnology, and health monitoring.\n*   **Future Outlook:** Further development and adoption of sophisticated implantable health technologies, pending ethical and regulatory frameworks.\n\n## Finance Executive Briefing\n\n**1. AI Integration in Financial Systems:** The financial industry is increasingly leveraging Artificial Intelligence for data-backed decision-making, influencing everything from trading strategies to risk assessment.\n\n*   **Market Implication:** Increased efficiency, improved accuracy in financial analysis, and the emergence of new AI-driven financial products.\n*   **Future Outlook:** AI will become indispensable for financial institutions, driving innovation and potentially creating new market dynamics.\n\n**2. Banking Consolidation and Resilience:** In regions like India, there's a government-led push for mega-mergers in the banking sector to create larger, more resilient institutions capable of global competition.\n\n*   **Market Implication:** Shifts in market structure, increased competition among larger entities, and a focus on operational efficiency.\n*   **Future Outlook:** Consolidation trends may continue globally, leading to a more concentrated banking landscape with enhanced stability.\n\n**3. Global Equity Market Volatility and Investor Caution:** Persistent inflation and higher interest rates are contributing to global equity market corrections and a general atmosphere of investor caution.\n\n*   **Market Implication:** Increased focus on risk management, scenario planning, and data-driven investment strategies. Potential for market dislocations creating opportunities.\n*   **Future Outlook:** Investors will likely remain vigilant, prioritizing robust analysis and adaptable strategies in a dynamic global economic environment.\nAggregatorAgent > ## Executive Summary: Intersecting Trends in Tech, Health, and Finance\n\n**Artificial Intelligence (AI)** is the unifying force across all three sectors, driving profound transformations. In technology, advancements in **Generative AI** and **Agentic AI** are revolutionizing content creation and automation, underpinned by massive investments in specialized hardware like GPUs and cloud infrastructure. This AI surge directly impacts finance, where it's enhancing decision-making, trading, and risk assessment, while also driving the need for sophisticated infrastructure orchestration.\n\nIn healthcare, AI is a game-changer, particularly in **AI-driven diagnostics**, promising earlier and more accurate disease detection within 3-7 years. This AI integration, alongside gene editing (CRISPR) and mRNA technology, is fueling a revolution in **personalized and proactive healthcare**.\n\nKey takeaways include:\n\n*   **AI Dominance:** AI is no longer a standalone trend but an enabler across industries, demanding robust infrastructure and explainability.\n*   **Personalization:** Both finance and health are moving towards highly individualized approaches, leveraging data and AI for tailored solutions.\n*   **Automation and Efficiency:** Agentic AI is poised to automate tasks, boosting efficiency in finance and logistics, and potentially improving access to mental healthcare.\n*   **Data-Driven Future:** The \"datafication\" of operations and the convergence of physical and digital experiences are reshaping business models and customer interactions.\n\nWhile market volatility and consolidation are noted in finance, the overarching theme is a future shaped by intelligent automation, personalized services, and the increasing integration of the digital and physical realms, with significant implications for innovation and efficiency across all sectors.\n","output_type":"stream"}],"execution_count":67},{"cell_type":"markdown","source":"üéâ Great! You've seen how parallel agents can dramatically speed up workflows by running independent tasks concurrently.\n\nSo far, all our workflows run from start to finish and then stop. **But what if you need to review and improve an output multiple times?** Next, we'll build a workflow that can loop and refine its own work.","metadata":{}},{"cell_type":"markdown","source":"---\n### Section 5\n## ‚û∞ Loop Workflows - The Refinement Cycle\n\n**The Problem: One-Shot Quality**\n\nAll the workflows we've seen so far run from start to finish. The `SequentialAgent` and `ParallelAgent` produce their final output and then stop. This 'one-shot' approach isn't good for tasks that require refinement and quality control. What if the first draft of our story is bad? We have no way to review it and ask for a rewrite.\n\n**The Solution: Iterative Refinement**\n\nWhen a task needs to be improved through cycles of feedback and revision, you can use a `LoopAgent`. A `LoopAgent` runs a set of sub-agents repeatedly *until a specific condition is met or a maximum number of iterations is reached.* This creates a refinement cycle, allowing the agent system to improve its own work over and over.\n\n**Use Loop when:** Iterative improvement is needed, quality refinement matters, or you need repeated cycles.\n\nTo learn more, check out the documentation related to [loop agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/).\n\n**Architecture: Story Writing & Critique Loop**\n\n<!--\n```mermaid\ngraph TD\n    A[\"Initial Prompt\"] -- > B[\"Writer Agent\"]\n    B -- >|story| C[\"Critic Agent\"]\n    C -- >|critique| D{\"Iteration < Max<br>AND<br>Not Approved?\"}\n    D -- >|Yes| B\n    D -- >|No| E[\"Final Story\"]\n\n    style B fill:#ccffcc\n    style C fill:#ffcccc\n    style D fill:#ffffcc\n```\n-->","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"markdown","source":"<img width=\"250\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/loop-agent.png\" alt=\"Loop Agent\" />","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Example: Iterative Story Refinement\n\nLet's build a system with two agents:\n\n1. **Writer Agent** - Writes a draft of a short story\n2. **Critic Agent** - Reviews and critiques the short story to suggest improvements","metadata":{"id":"fP4I3mvtBtHF"}},{"cell_type":"code","source":"# This agent runs ONCE at the beginning to create the first draft.\ninitial_writer_agent = Agent(\n    name=\"InitialWriterAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"Based on the user's prompt, write the first draft of a short story (around 100-150 words).\n    Output only the story text, with no introduction or explanation.\"\"\",\n    output_key=\"current_story\", # Stores the first draft in the state.\n)\n\nprint(\"‚úÖ initial_writer_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:24:23.812568Z","iopub.execute_input":"2025-11-10T09:24:23.812914Z","iopub.status.idle":"2025-11-10T09:24:23.818633Z","shell.execute_reply.started":"2025-11-10T09:24:23.812888Z","shell.execute_reply":"2025-11-10T09:24:23.817368Z"}},"outputs":[{"name":"stdout","text":"‚úÖ initial_writer_agent created.\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"# This agent's only job is to provide feedback or the approval signal. It has no tools.\ncritic_agent = Agent(\n    name=\"CriticAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a constructive story critic. Review the story provided below.\n    Story: {current_story}\n    \n    Evaluate the story's plot, characters, and pacing.\n    - If the story is well-written and complete, you MUST respond with the exact phrase: \"APPROVED\"\n    - Otherwise, provide 2-3 specific, actionable suggestions for improvement.\"\"\",\n    output_key=\"critique\", # Stores the feedback in the state.\n)\n\nprint(\"‚úÖ critic_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:24:26.749960Z","iopub.execute_input":"2025-11-10T09:24:26.750762Z","iopub.status.idle":"2025-11-10T09:24:26.755873Z","shell.execute_reply.started":"2025-11-10T09:24:26.750736Z","shell.execute_reply":"2025-11-10T09:24:26.754749Z"}},"outputs":[{"name":"stdout","text":"‚úÖ critic_agent created.\n","output_type":"stream"}],"execution_count":69},{"cell_type":"markdown","source":"Now, we need a way for the loop to actually stop based on the critic's feedback. The `LoopAgent` itself doesn't automatically know that \"APPROVED\" means \"stop.\"\n\nWe need an agent to give it an explicit signal to terminate the loop.\n\nWe do this in two parts:\n\n1. A simple Python function that the `LoopAgent` understands as an \"exit\" signal.\n2. An agent that can call that function when the right condition is met.\n\nFirst, you'll define the `exit_loop` function:","metadata":{}},{"cell_type":"code","source":"# This is the function that the RefinerAgent will call to exit the loop.\ndef exit_loop():\n    \"\"\"Call this function ONLY when the critique is 'APPROVED', indicating the story is finished and no more changes are needed.\"\"\"\n    return {\"status\": \"approved\", \"message\": \"Story approved. Exiting refinement loop.\"}\n\nprint(\"‚úÖ exit_loop function created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:24:31.487387Z","iopub.execute_input":"2025-11-10T09:24:31.487712Z","iopub.status.idle":"2025-11-10T09:24:31.493125Z","shell.execute_reply.started":"2025-11-10T09:24:31.487690Z","shell.execute_reply":"2025-11-10T09:24:31.492059Z"}},"outputs":[{"name":"stdout","text":"‚úÖ exit_loop function created.\n","output_type":"stream"}],"execution_count":70},{"cell_type":"markdown","source":"To let an agent call this Python function, we wrap it in a `FunctionTool`. Then, we create a `RefinerAgent` that has this tool.\n\nüëâ **Notice its instructions:** this agent is the \"brain\" of the loop. It reads the `{critique}` from the `CriticAgent` and decides whether to (1) call the `exit_loop` tool or (2) rewrite the story.","metadata":{}},{"cell_type":"code","source":"# This agent refines the story based on critique OR calls the exit_loop function.\nrefiner_agent = Agent(\n    name=\"RefinerAgent\",\n    model=\"gemini-2.5-flash-lite\",\n    instruction=\"\"\"You are a story refiner. You have a story draft and critique.\n    \n    Story Draft: {current_story}\n    Critique: {critique}\n    \n    Your task is to analyze the critique.\n    - IF the critique is EXACTLY \"APPROVED\", you MUST call the `exit_loop` function and nothing else.\n    - OTHERWISE, rewrite the story draft to fully incorporate the feedback from the critique.\"\"\",\n    \n    output_key=\"current_story\", # It overwrites the story with the new, refined version.\n    tools=[FunctionTool(exit_loop)], # The tool is now correctly initialized with the function reference.\n)\n\nprint(\"‚úÖ refiner_agent created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:24:34.225276Z","iopub.execute_input":"2025-11-10T09:24:34.225605Z","iopub.status.idle":"2025-11-10T09:24:34.231682Z","shell.execute_reply.started":"2025-11-10T09:24:34.225581Z","shell.execute_reply":"2025-11-10T09:24:34.230721Z"}},"outputs":[{"name":"stdout","text":"‚úÖ refiner_agent created.\n","output_type":"stream"}],"execution_count":71},{"cell_type":"markdown","source":"Then we bring the agents together under a loop agent, which is itself nested inside of a sequential agent.\n\nThis design ensures that the system first produces an initial story draft, then the refinement loop runs up to the specified number of `max_iterations`:","metadata":{}},{"cell_type":"code","source":"# The LoopAgent contains the agents that will run repeatedly: Critic -> Refiner.\nstory_refinement_loop = LoopAgent(\n    name=\"StoryRefinementLoop\",\n    sub_agents=[critic_agent, refiner_agent],\n    max_iterations=2, # Prevents infinite loops\n)\n\n# The root agent is a SequentialAgent that defines the overall workflow: Initial Write -> Refinement Loop.\nroot_agent = SequentialAgent(\n    name=\"StoryPipeline\",\n    sub_agents=[initial_writer_agent, story_refinement_loop],\n)\n\nprint(\"‚úÖ Loop and Sequential Agents created.\")","metadata":{"id":"a2b8WlJoBtHF","outputId":"13ed1e15-dcf9-4e1d-ad1e-fb18ee793de5","trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:24:36.532096Z","iopub.execute_input":"2025-11-10T09:24:36.532638Z","iopub.status.idle":"2025-11-10T09:24:36.537980Z","shell.execute_reply.started":"2025-11-10T09:24:36.532609Z","shell.execute_reply":"2025-11-10T09:24:36.537072Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Loop and Sequential Agents created.\n","output_type":"stream"}],"execution_count":72},{"cell_type":"markdown","source":"Let's run the agent and give it a topic to write a short story about:","metadata":{}},{"cell_type":"code","source":"runner = InMemoryRunner(agent=root_agent)\nresponse = await runner.run_debug(\"Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-10T09:24:38.848827Z","iopub.execute_input":"2025-11-10T09:24:38.849110Z","iopub.status.idle":"2025-11-10T09:24:45.635902Z","shell.execute_reply.started":"2025-11-10T09:24:38.849091Z","shell.execute_reply":"2025-11-10T09:24:45.635137Z"}},"outputs":[{"name":"stdout","text":"\n ### Created new session: debug_session_id\n\nUser > Write a short story about a lighthouse keeper who discovers a mysterious, glowing map\nInitialWriterAgent > The salt spray was Elias‚Äôs constant companion, misting his beard and clinging to the worn stone of the lighthouse. For twenty years, the rhythmic sweep of the beam had been his only companion. One blustery evening, while tidying the lamp room, his hand brushed against a loose brick. Behind it lay a rolled parchment, brittle with age. Unfurling it, Elias gasped. It wasn't paper, but some sort of treated kelp, and etched upon it was a map, glowing with an eerie, internal light. Strange, serpentine lines marked unknown coastlines, and at its center pulsed a single, emerald star. His heart hammered. This was no ordinary chart.\nCriticAgent > This is a promising start to a story! Here are a few suggestions for improvement:\n\n*   **Character Depth:** Elias's isolation for twenty years is established, but his reaction to the map feels a little generic (\"His heart hammered\"). Consider adding a specific thought or feeling that reflects his long solitude. Does he feel a flicker of excitement for adventure, a pang of fear at the unknown, or perhaps a deep, almost forgotten longing? Showing his inner world will make him a more relatable character.\n*   **Sensory Details & World-Building:** The description of the map is good, particularly the \"treated kelp\" and \"eerie, internal light.\" To further immerse the reader, you could expand on the map's strangeness. What do the \"serpentine lines\" look like beyond just being lines? Are they textured? Do they shift slightly? Does the emerald star emit any sound or warmth? These details can enhance the mystery and make the discovery more impactful.\n*   **Plot Hook Clarity:** The discovery is intriguing, but the \"plot\" is currently just the discovery itself. To propel the narrative forward, consider hinting at *why* this map might have been hidden or *what* the emerald star might represent. Is it a treasure? A warning? A gateway? A brief internal thought from Elias about the *possibility* of what the map could lead to would create a stronger hook for what comes next.\nRefinerAgent > The salt spray was Elias‚Äôs constant companion, misting his beard and clinging to the worn stone of the lighthouse. For twenty years, the rhythmic sweep of the beam had been his only companion, a silent sentinel in his solitary existence. One blustery evening, while tidying the lamp room, his hand brushed against a loose brick. Behind it lay a rolled parchment, brittle with age. Unfurling it, Elias gasped, not just from the surprise, but from a sudden, almost forgotten surge of longing for a life beyond the endless sea. It wasn't paper, but some sort of treated kelp, cool and slightly yielding to the touch, and etched upon it was a map, glowing with an eerie, internal light. Strange, serpentine lines, like petrified currents, coiled across its surface, hinting at unknown coastlines that seemed to writhe subtly under his gaze. At its center pulsed a single, emerald star, radiating a faint, almost inaudible hum and a warmth that belied its visual coldness. His heart hammered, a frantic rhythm against the quiet solitude of his life. This was no ordinary chart. Was it a siren‚Äôs call to forgotten riches, a cartographer‚Äôs cryptic warning, or a gateway to a world he‚Äôd only glimpsed in the wild dreams of his youth? Elias traced the glowing lines, the strange map a sudden, vibrant counterpoint to the grey monotony of his years, a promise of the unknown that whispered directly to the dormant adventurer within him.\nCriticAgent > APPROVED\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"}],"execution_count":73},{"cell_type":"markdown","source":"You've now implemented a loop agent, creating a sophisticated system that can iteratively review and improve its own output. This is a key pattern for ensuring high-quality results.\n\nYou now have a complete toolkit of workflow patterns. Let's put it all together and review how to choose the right one for your use case.","metadata":{}},{"cell_type":"markdown","source":"--- \n### Section 6\n## Summary - Choosing the Right Pattern\n\n### Decision Tree: Which Workflow Pattern?\n\n<!--\n```mermaid\ngraph TD\n    A{\"What kind of workflow do you need?\"} -- > B[\"Fixed Pipeline<br>(A ‚Üí B ‚Üí C)\"];\n    A -- > C[\"Concurrent Tasks<br>(Run A, B, C all at once)\"];\n    A -- > D[\"Iterative Refinement<br>(A ‚áÜ B)\"];\n    A -- > E[\"Dynamic Decisions<br>(Let the LLM decide what to do)\"];\n\n    B -- > B_S[\"Use <b>SequentialAgent</b>\"];\n    C -- > C_S[\"Use <b>ParallelAgent</b>\"];\n    D -- > D_S[\"Use <b>LoopAgent</b>\"];\n    E -- > E_S[\"Use <b>LLM Orchestrator</b><br>(Agent with other agents as tools)\"];\n\n    style B_S fill:#f9f,stroke:#333,stroke-width:2px\n    style C_S fill:#ccf,stroke:#333,stroke-width:2px\n    style D_S fill:#cff,stroke:#333,stroke-width:2px\n    style E_S fill:#cfc,stroke:#333,stroke-width:2px\n```\n-->","metadata":{"id":"-CKnXSHWBtHF"}},{"cell_type":"markdown","source":"<img width=\"1000\" src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day1/agent-decision-tree.png\" alt=\"Agent Decision Tree\" />","metadata":{}},{"cell_type":"markdown","source":"### Quick Reference Table\n\n| Pattern | When to Use | Example | Key Feature |\n|---------|-------------|---------|-------------|\n| **LLM-based (sub_agents)** | Dynamic orchestration needed | Research + Summarize | LLM decides what to call |\n| **Sequential** | Order matters, linear pipeline | Outline ‚Üí Write ‚Üí Edit | Deterministic order |\n| **Parallel** | Independent tasks, speed matters | Multi-topic research | Concurrent execution |\n| **Loop** | Iterative improvement needed | Writer + Critic refinement | Repeated cycles |","metadata":{"id":"-CKnXSHWBtHF","jp-MarkdownHeadingCollapsed":true}},{"cell_type":"markdown","source":"---\n\n## ‚úÖ Congratulations! You're Now an Agent Orchestrator\n\nIn this notebook, you made the leap from a single agent to a **multi-agent system**.\n\nYou saw **why** a team of specialists is easier to build and debug than one \"do-it-all\" agent. Most importantly, you learned how to be the **director** of that team.\n\nYou used `SequentialAgent`, `ParallelAgent`, and `LoopAgent` to create deterministic workflows, and you even used an LLM as a 'manager' to make dynamic decisions. You also mastered the \"plumbing\" by using `output_key` to pass state between agents and make them collaborative.\n\n**‚ÑπÔ∏è Note: No submission required!**\n\nThis notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n### üìö Learn More\n\nRefer to the following documentation to learn more:\n\n- [Agents in ADK](https://google.github.io/adk-docs/agents/)\n- [Sequential Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/sequential-agents/)\n- [Parallel Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/parallel-agents/)\n- [Loop Agents in ADK](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/)\n- [Custom Agents in ADK](https://google.github.io/adk-docs/agents/custom-agents/)\n\n### üéØ Next Steps\n\nReady for the next challenge? Stay tuned for Day 2 notebooks where we'll learn how to create **Custom Functions, use MCP Tools** and manage **Long-Running operations!**","metadata":{}},{"cell_type":"markdown","source":"---\n\n| Authors |\n| --- |\n| [Kristopher Overholt](https://www.linkedin.com/in/koverholt) |","metadata":{}}]}